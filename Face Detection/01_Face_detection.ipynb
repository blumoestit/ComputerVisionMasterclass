{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "governing-logan",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-bachelor",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-ukraine",
   "metadata": {},
   "source": [
    "### Loading the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proof-celebrity",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "working-essay",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/magdalenablum-oeste/Google Drive/GitHubMBO/ComputerVisionMasterclass/Face Detection\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "precise-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mounted-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/people1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "disturbed-crime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1920, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "broad-diploma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('image window', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-design",
   "metadata": {},
   "source": [
    "### Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sunrise-designer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.resize(image, (800, 600))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rotary-basket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('image-resized window', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-seventh",
   "metadata": {},
   "source": [
    "### Image gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "outstanding-display",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('image gray', image_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fabulous-peninsula",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-place",
   "metadata": {},
   "source": [
    "## Detecting Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-cheat",
   "metadata": {},
   "source": [
    "### Cascade Classifier\n",
    "We use gray scale images to reduce the size of the image (from three to one channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-poster",
   "metadata": {},
   "source": [
    "#### Load detector based on AdaBoost algorithm\n",
    "[Medium article](https://medium.com/neurosapiens/face-detectionface-11f77c9f4f3f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "familiar-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "casual-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = face_detector.detectMultiScale(image_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "controlling-integral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115, 124,  53,  53],\n",
       "       [677,  72,  68,  68],\n",
       "       [475, 123,  59,  59],\n",
       "       [387, 233,  73,  73],\n",
       "       [ 92, 239,  66,  66],\n",
       "       [390, 323,  56,  56]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections\n",
    "# two first numbers are x, y coordinates of the recognized face\n",
    "# two last numbers show the size of the detected face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "respected-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detections) # each row indicate a face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-butter",
   "metadata": {},
   "source": [
    "#### Draw boxes around the faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "exact-apollo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (x, y, w, h) in detections:\n",
    "    #print(x, y, w, h)\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "cv2.imshow('image gray', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-glass",
   "metadata": {},
   "source": [
    "#### Add Haarcascade parameters\n",
    "This algorithm recognized one region as a face in the picture but it is not a face -> Add Haarcascade parameters: `scaleFactor`must be > 1 (depends on the image size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cellular-cooperative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('Images/people1.jpg')\n",
    "image = cv2.resize(image, (800, 600))\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "detections = face_detector.detectMultiScale(image_gray, scaleFactor = 1.09)\n",
    "for (x, y, w, h) in detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0,255,0), 5)\n",
    "cv2.imshow('image fine detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-sleeve",
   "metadata": {},
   "source": [
    "### Using other picture\n",
    "When the picture is not resized and faces are not stretched, the result shows less false positive and false negative. Use `minNeighbor`  and `minSize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "streaming-switzerland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('Images/people2.jpg')\n",
    "#image = cv2.resize(image, (800, 600))\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "detections = face_detector.detectMultiScale(image_gray, \n",
    "                                            scaleFactor=1.2,\n",
    "                                            minNeighbors=7,\n",
    "                                            minSize=(25,25))\n",
    "for (x, y, w, h) in detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0,255,0), 3)\n",
    "cv2.imshow('image fine detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-arabic",
   "metadata": {},
   "source": [
    "### Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "frequent-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('Images/people1.jpg')\n",
    "image = cv2.resize(image, (800, 600))\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "detections = face_detector.detectMultiScale(image_gray, \n",
    "                                            scaleFactor = 1.09)\n",
    "\n",
    "for (x, y, w, h) in detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow('image fine detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fundamental-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_detector = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "interpreted-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 49\n",
      "44 44\n",
      "46 46\n",
      "34 34\n",
      "35 35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('Images/people1.jpg')\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_detections = face_detector.detectMultiScale(image_gray, scaleFactor = 1.3, minSize = (30,30))\n",
    "for (x, y, w, h) in face_detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0,255,0), 2)\n",
    "\n",
    "eye_detections = eye_detector.detectMultiScale(image_gray, scaleFactor = 1.1, minNeighbors=10, maxSize=(70,70))\n",
    "for (x, y, w, h) in eye_detections:\n",
    "    print(w, h)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "    \n",
    "cv2.imshow('image eye detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "organizational-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n",
      "41 41\n",
      "48 48\n",
      "44 44\n",
      "33 33\n",
      "36 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread('Images/We.jpg')\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#image = cv2.resize(image, (1000, 600))\n",
    "face_detections = face_detector.detectMultiScale(image_gray, \n",
    "                                                 scaleFactor = 1.3, \n",
    "                                                 minSize = (30,30)\n",
    "                                                )\n",
    "for (x, y, w, h) in face_detections:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0,255,0), 2)\n",
    "\n",
    "eye_detections = eye_detector.detectMultiScale(image_gray, \n",
    "                                               scaleFactor = 1.042, # low value detects more objects (false positive)\n",
    "                                               minNeighbors=10, \n",
    "                                               maxSize=(100,100) # numbers depend on image size\n",
    "                                              )\n",
    "for (x, y, w, h) in eye_detections:\n",
    "    print(w, h)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "    \n",
    "cv2.imshow('image eye detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-audit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-aruba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
